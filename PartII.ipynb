{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "eps=np.finfo(float).eps\n",
    "from binarytree import tree,Node\n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from operator import itemgetter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop(['left','sales','salary'],axis=1)\n",
    "X = pd.concat([X,pd.get_dummies(df['sales'], prefix='sales')],axis=1)\n",
    "X = pd.concat([X,pd.get_dummies(df['salary'], prefix='salary')],axis=1)\n",
    "y=df['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "orignalX=copy.deepcopy(X_train)\n",
    "orignalY=copy.deepcopy(y_train)\n",
    "testX=copy.deepcopy(X_test)\n",
    "testY=copy.deepcopy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findParentEntropy(df):\n",
    "    if df.empty==True:\n",
    "        return\n",
    "    classCol=df.keys()[-1]\n",
    "    #yeh sirf header return karega\n",
    "    resultValues=df[classCol].unique()\n",
    "    #all ouput values in output column\n",
    "    entropy=0\n",
    "    for value in resultValues:\n",
    "        fraction=df[classCol].value_counts()[value]/(len(df[classCol])+eps)\n",
    "        entropy+=-fraction*np.log2(fraction+eps)\n",
    "    return abs(entropy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRelativeEntropy(df,attribute):\n",
    "    if df.empty==True:\n",
    "        return\n",
    "    classCol= df.keys()[-1] \n",
    "    #last col assumed as result \n",
    "    #getting target class \n",
    "    resultValues=df[classCol].unique() \n",
    "    attributeNames=df[attribute].unique()\n",
    "    entropy2 = 0\n",
    "    for attr in attributeNames:\n",
    "        entropy = 0\n",
    "        for value in resultValues:\n",
    "            #temp&hot with yes\n",
    "            num = len(df[attribute][df[attribute]==attr][df[classCol]==value])\n",
    "            #total hot\n",
    "            den = len(df[attribute][df[attribute]==attr])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        #entropy attribute/total*(entropy attribute_values)\n",
    "        fraction2 = den/len(df)  \n",
    "        entropy2 += -fraction2*entropy \n",
    "    return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node,value):\n",
    "    return df[df[node] == value].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtableSmaller(df, node,value):\n",
    "    if df.empty==True:\n",
    "        return\n",
    "    return df[df[node] < value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtableGreater(df, node,value):\n",
    "    if df.empty==True:\n",
    "        return\n",
    "    return df[df[node] >= value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestAttribute(df):\n",
    "    if df.empty==True:\n",
    "        return\n",
    "    infoGain=[]\n",
    "    for key in df.keys()[:-1]:\n",
    "        infoGain.append(findParentEntropy(df)-findRelativeEntropy(df,key))\n",
    "    return df.keys()[:-1][np.argmax(infoGain)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_evaluation\n",
      "satisfaction_level\n",
      "average_montly_hours\n",
      "time_spend_company\n",
      "number_project\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=pd.concat([X_train,y_train],axis=1)\n",
    "splitpoint={}\n",
    "numeric=['last_evaluation','satisfaction_level','average_montly_hours','time_spend_company','number_project']\n",
    "for col in numeric:\n",
    "    df.sort_values(col,inplace=True)\n",
    "    prev=None;\n",
    "    value=0;\n",
    "    max1=0;\n",
    "    print(col)\n",
    "    for index,row in df.iterrows():\n",
    "        if prev is not None:\n",
    "            if prev['left'] != row['left']:\n",
    "                mid=(float(prev[col])+float(row[col]))/2\n",
    "                subtableLeft=get_subtableSmaller(df,col,mid)\n",
    "                subtableRight=get_subtableGreater(df,col,mid)\n",
    "                fraction=len(subtableLeft)/len(df)\n",
    "                fraction1=len(subtableRight)/len(df)\n",
    "                entropy1=findParentEntropy(df)\n",
    "#                 print(subtableLeft)\n",
    "#                 a=input()\n",
    "                firstSubtable=0\n",
    "                secondSubtable=0\n",
    "                if subtableLeft.empty:\n",
    "                    firstSubtable=0\n",
    "                else:\n",
    "                    firstSubtable=fraction*findParentEntropy(subtableLeft)\n",
    "#                 print(subtableRight)\n",
    "                if subtableRight.empty:\n",
    "                    secondSubtable=0\n",
    "                else:\n",
    "                    secondSubtable=fraction1*findParentEntropy(subtableRight)\n",
    "                    \n",
    "                entropy2=firstSubtable+secondSubtable\n",
    "                ig1=abs(entropy1)-abs(entropy2)\n",
    "\n",
    "                if ig1>max1:\n",
    "                    max1=ig1\n",
    "                    value=mid\n",
    "        prev=row\n",
    "    splitpoint[col]=value \n",
    "    for index,row1 in X_train.iterrows():\n",
    "        if float(row1[col])<value:\n",
    "            X_train.at[index,col]=0\n",
    "        else:\n",
    "            X_train.at[index,col]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "# print(value)\n",
    "# print(max1)\n",
    "df=pd.concat([X_train,y_train],axis=1)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self,value,left=None,right=None):\n",
    "        self.value=value\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.positive=0\n",
    "        self.negative=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(df):\n",
    "    if len(df.columns)==1:\n",
    "        return\n",
    "    \n",
    "    resultLabel= df.keys()[-1] \n",
    "    clValue,counts = np.unique(df[resultLabel],return_counts=True)\n",
    "    attribute_name=bestAttribute(df)\n",
    "#     attValue = np.unique(df[attribute_name])\n",
    "    root=node(attribute_name)\n",
    "    \n",
    "    if len(counts)<=1:\n",
    "        if clValue[0]==0:\n",
    "            root.negative=counts[0]\n",
    "        else:\n",
    "            root.positive=counts[0]\n",
    "    else:\n",
    "        root.positive=counts[1]\n",
    "        root.negative=counts[0]\n",
    "            \n",
    "            \n",
    "#         for value in attValue:\n",
    "#             print(type(value))\n",
    "        \n",
    "        subtable0 = get_subtable(df,attribute_name,0)\n",
    "        subtable0 =subtable0.drop([attribute_name],axis=1)\n",
    "        subtable1 = get_subtable(df,attribute_name,1)\n",
    "        subtable1 =subtable1.drop([attribute_name],axis=1)\n",
    "        clValue,countleft = np.unique(subtable0[resultLabel],return_counts=True)\n",
    "        clValue1,countright = np.unique(subtable1[resultLabel],return_counts=True)\n",
    "        if(len(countleft)<=1):\n",
    "            pass\n",
    "        else:\n",
    "            root.left=buildTree(subtable0) #Calling the function recursively\n",
    "        if(len(countright)<=1):\n",
    "            pass\n",
    "        else:\n",
    "            root.right=buildTree(subtable1)\n",
    "       \n",
    "                   \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfaction_level\n"
     ]
    }
   ],
   "source": [
    "# print(df)\n",
    "root=buildTree(df)\n",
    "print(root.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spend_company\n",
      "<__main__.node object at 0x7f72e988b908>\n",
      "number_project\n",
      "last_evaluation\n",
      "average_montly_hours\n",
      "2112 6878\n"
     ]
    }
   ],
   "source": [
    "print(root.right.value)\n",
    "print(root.right.left)\n",
    "print(root.left.value)\n",
    "print(root.left.left.value)\n",
    "print(root.left.right.value)\n",
    "print(root.positive,root.negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(row1,root):\n",
    "    #     if root==None:\n",
    "    #         return \n",
    "        #print(root.value)\n",
    "        if root.left==None and root.right==None:\n",
    "            if root.positive > root.negative:\n",
    "                y1.append(1)\n",
    "            else:\n",
    "                y1.append(0)\n",
    "            return\n",
    "    #     for i in row1.keys():\n",
    "    #         if i==root.value:\n",
    "        i=root.value\n",
    "        if i in row1:\n",
    "            \n",
    "            if row1[i]==0:\n",
    "        #         print(\"000\")\n",
    "                if root.left==None:\n",
    "                    if root.positive > root.negative:\n",
    "                        y1.append(1)\n",
    "                        return\n",
    "                    else:\n",
    "                        y1.append(0)\n",
    "                        return\n",
    "                else:\n",
    "                    testing(row1,root.left)\n",
    "            else:\n",
    "        #         print(\"111\")\n",
    "                if root.right==None:\n",
    "                    if root.positive > root.negative:\n",
    "                        y1.append(1)\n",
    "                        return\n",
    "                    else:\n",
    "                        y1.append(0)\n",
    "                        return \n",
    "                else:\n",
    "                    testing(row1,root.right)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive > root.negative:\n",
    "                    y1.append(1)\n",
    "                    return\n",
    "                else:\n",
    "                    y1.append(0)\n",
    "                    return\n",
    "            else:\n",
    "                testing(row1,root.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_evaluation': 0.575, 'satisfaction_level': 0.46499999999999997, 'average_montly_hours': 287.5, 'time_spend_company': 3.0, 'number_project': 3.0}\n"
     ]
    }
   ],
   "source": [
    "#X_test\n",
    "print(splitpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2248\n"
     ]
    }
   ],
   "source": [
    "def testingData(df):\n",
    "    for index,row in df.iterrows():\n",
    "        testing(row,root)\n",
    "\n",
    "y1=[] \n",
    "for col in numeric:\n",
    "    value=splitpoint[col]\n",
    "    for index,row1 in X_test.iterrows():\n",
    "            if float(row1[col])<value:\n",
    "                X_test.at[index,col]=0\n",
    "            else:\n",
    "                X_test.at[index,col]=1\n",
    "# X_test\n",
    "testingData(X_test)  \n",
    "print(len(y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1628   57]\n",
      " [ 264  299]]\n",
      "0.8572064056939501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1685\n",
      "           1       0.84      0.53      0.65       563\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2248\n",
      "   macro avg       0.85      0.75      0.78      2248\n",
      "weighted avg       0.86      0.86      0.85      2248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y1))  \n",
    "print(accuracy_score(y_test,y1))\n",
    "print(classification_report(y_test, y1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData=pd.read_csv(\"sample_test.csv\")\n",
    "XInput =inputData.drop(['sales','salary'],axis=1)\n",
    "XInput = pd.concat([XInput,pd.get_dummies(inputData['sales'], prefix='sales')],axis=1)\n",
    "XInput = pd.concat([XInput,pd.get_dummies(inputData['salary'], prefix='salary')],axis=1)\n",
    "y1=[] \n",
    "for col in numeric:\n",
    "    value=splitpoint[col]\n",
    "    for index,row1 in XInput.iterrows():\n",
    "            if float(row1[col])<value:\n",
    "                XInput.at[index,col]=0\n",
    "            else:\n",
    "                XInput.at[index,col]=1\n",
    "testingData(XInput) \n",
    "\n",
    "# yInput=df['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1648   37]\n",
      " [  22  541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1685\n",
      "           1       0.94      0.96      0.95       563\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.96      0.97      0.97      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9737544483985765\n"
     ]
    }
   ],
   "source": [
    "# classifier = DecisionTreeClassifier()\n",
    "# classifier.fit(orignalX, orignalY)  \n",
    "# y_pred = classifier.predict(testX)  \n",
    "# print(confusion_matrix(testY, y_pred))  \n",
    "# print(classification_report(testY, y_pred)) \n",
    "# print(accuracy_score(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(XInput)  \n",
    "# print(confusion_matrix(testY, y_pred))  \n",
    "# print(classification_report(testY, y_pred)) \n",
    "# print(accuracy_score(testY,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2248, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-27582b4b8b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2248, 2]"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(confusion_matrix(y_pred, y1))  \n",
    "# print(accuracy_score(y_pred,y1))\n",
    "# print(classification_report(y_pred, y1)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
